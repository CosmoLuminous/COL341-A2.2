{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490aab6-378c-474c-bdaf-1d27f220e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf888b97-c936-4d4d-b35e-2860fbf40bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader Class\n",
    "# if BATCH_SIZE = N, dataloader returns images tensor of size [N, C, H, W] and labels [N]\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_csv, train = True , img_transform=None):\n",
    "        \"\"\"\n",
    "        Dataset init function\n",
    "        \n",
    "        INPUT:\n",
    "        data_csv: Path to csv file containing [data, labels]\n",
    "        train: \n",
    "            True: if the csv file has [labels,data] (Train data and Public Test Data) \n",
    "            False: if the csv file has only [data] and labels are not present.\n",
    "        img_transform: List of preprocessing operations need to performed on image. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_csv = data_csv\n",
    "        self.img_transform = img_transform\n",
    "        self.is_train = train\n",
    "        \n",
    "        data = pd.read_csv(data_csv, header=None)\n",
    "        if self.is_train:\n",
    "            images = data.iloc[:,1:].to_numpy()\n",
    "            labels = data.iloc[:,0].astype(int)\n",
    "        else:\n",
    "            images = data.iloc[:,:]\n",
    "            labels = None\n",
    "        \n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        print(\"Total Images: {}, Data Shape = {}\".format(len(self.images), images.shape))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of samples in the dataset\"\"\"\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads image of the given index and performs preprocessing.\n",
    "        \n",
    "        INPUT: \n",
    "        idx: index of the image to be loaded.\n",
    "        \n",
    "        OUTPUT:\n",
    "        sample: dictionary with keys images (Tensor of shape [1,C,H,W]) and labels (Tensor of labels [1]).\n",
    "        \"\"\"\n",
    "        image = self.images[idx]\n",
    "        image = np.array(image).astype(np.uint8).reshape(32, 32, 3)\n",
    "        \n",
    "        if self.is_train:\n",
    "            label = self.labels[idx]\n",
    "        else:\n",
    "            label = -1\n",
    "        \n",
    "        image = self.img_transform(image)\n",
    "        \n",
    "        sample = {\"images\": image, \"labels\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd43199-7b15-41bf-8c5a-a2af0d286b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader Usage\n",
    "\n",
    "BATCH_SIZE = 200 # Batch Size. Adjust accordingly\n",
    "NUM_WORKERS = 20 # Number of threads to be used for image loading. Adjust accordingly.\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "\n",
    "# Train DataLoader\n",
    "train_data = \"\" # Path to train csv file\n",
    "train_data = \"/mnt/scratch1/siy197580/COL341/cifar/train_data.csv\"\n",
    "test_data = \"/mnt/scratch1/siy197580/COL341/cifar/public_test.csv\"\n",
    "train_dataset = ImageDataset(data_csv = train_data, train=True, img_transform=img_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)\n",
    "\n",
    "# Test DataLoader\n",
    "test_data = \"\" # Path to test csv file\n",
    "train_data = \"/mnt/scratch1/siy197580/COL341/cifar/train_data.csv\"\n",
    "test_data = \"/mnt/scratch1/siy197580/COL341/cifar/public_test.csv\"\n",
    "test_dataset = ImageDataset(data_csv = test_data, train=True, img_transform=img_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers = NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676893e-7600-47d3-ba51-d59177a0bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumeration for 1 epoch\n",
    "for batch_idx, sample in enumerate(train_loader):\n",
    "    images = sample['images']\n",
    "    labels = sample['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515cf0e-3939-428b-9a68-3ef2d889462b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
